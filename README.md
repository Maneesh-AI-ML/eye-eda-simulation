# Eye Tracking & EDA Signal Integration (Simulated)

This project simulates a realistic experimental pipeline that combines **eye tracking** and **electrodermal activity (EDA)** signals in response to visual stimuli â€” inspired by human behavior studies in immersive environments like those in the CONTINUUM platform.

## ğŸ§ª Project Goals

- Simulate gaze and EDA signals for 3 stimuli: Happy Child, Angry Dog, and Neutral Scene
- Align and synchronize data using timestamps
- Apply signal filtering (Butterworth low-pass) to clean EDA
- Detect and visualize SCR (Skin Conductance Responses)
- Combine gaze + EDA to interpret emotional & attention response together

## ğŸ“ Folder Structure

```bash
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ realistic_eda_eye_pipeline.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ [eye_tracking_data].csv
â”‚   â”œâ”€â”€ [eda_data].csv
â”‚   â””â”€â”€ [stimuli].csv
â”œâ”€â”€ images/
â”‚   â””â”€â”€ [plots].png

## ğŸ› ï¸ Tools & Libraries

- Python  
- Pandas, NumPy  
- Matplotlib  
- SciPy (signal processing)  
- Jupyter Notebook

## ğŸ“Š Outputs

- Filtered EDA signal with SCR peaks  
- Combined plot of gaze + EDA + stimulus timeline  
- Time-locked multimodal visualization

## ğŸ‘¤ Author

**Maneesh Mishra**  
PhD in Automatique et Productique  
UniversitÃ© de Lille  
ğŸŒ [LinkedIn](https://www.linkedin.com/in//maneesh-ai-ml/)
)  
ğŸ“« Contact: maneesh09mishra@gmail.com

## ğŸ“„ License

This project is licensed under the MIT License.
